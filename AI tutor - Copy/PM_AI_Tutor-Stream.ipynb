{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "509fae34-4703-41e2-a058-ce34631bd7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeeec9de-9535-436d-87ce-50e699fcf79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x27149bcb1d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client_Session = OpenAI(api_key=openai_api_key)\n",
    "client_Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99ecf2a7-7288-43dd-bf49-b644abf79177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (5.45.0)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (4.2.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (1.1.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (0.116.1)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (0.6.1)\n",
      "Requirement already satisfied: gradio-client==1.13.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (1.13.0)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (0.34.4)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (3.11.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (10.4.0)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (2.8.2)\n",
      "Requirement already satisfied: pydub in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (0.13.0)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (0.47.3)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (0.17.4)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (4.11.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio) (0.35.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio-client==1.13.0->gradio) (2024.6.1)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from gradio-client==1.13.0->gradio) (15.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.66.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.20.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.2.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mrudu\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "226de568-6f9b-4232-90fe-3648b2e4e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Ai_tutor_response_stream (user_question):\n",
    "    system_prompt = \"You are a Product Manager with 30 years of experience in the US as SaaS PM. You are very patient and understanding, explain the questions that a fresher in PM askes in the domain of Product management and Business Management. Also suggest some Youtube videos to watch on the concept asked, books to read or any resource that might be helpful\"\n",
    "    try:\n",
    "        stream=client_Session.chat.completions.create(model = \"gpt-4o-mini\", \n",
    "                                                      messages = [{\"role\":\"system\", \"content\":system_prompt},\n",
    "                                                                  {\"role\" : \"user\", \"content\" :user_question}], \n",
    "                                                      temperature = 0.7, stream = True)\n",
    "        #the value of temperature is between 0 to 2\n",
    "\n",
    "        full_response=\"\"\n",
    "        for chunck in stream:\n",
    "            if chunck.choices[0].delta and chunck.choices[0].delta.content:\n",
    "                text_chunck= chunck.choices[0].delta.content\n",
    "                full_response+=text_chunck\n",
    "                yield full_response \n",
    "            #the yeild operator acts as streaming function\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"sorry, some error occurred\",e)\n",
    "        yield f\"there is some error:{e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2d3be6f-4834-4c84-a600-fe30cc2446f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanantion_levels = {1: \"Like I'm 5 years old\",\n",
    "                       2: \"Like I'm 10 years old\",\n",
    "                       3: \"Like I'm Undergraduation student\",\n",
    "                       4: \"Like I'm Masters student\",\n",
    "                       5: \"Like I have completed Phd\",\n",
    "                       6: \"Like I have 15+ years of experience in the industry\"\n",
    "                      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d3b27c7-e03d-4cc9-b4b5-43e85be79ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a new function that streams the response\n",
    "def stream_ai_tutor_response(user_question, explanation_level_value):\n",
    "\n",
    "    level_description = explanantion_levels.get(explanation_level_value, \"clearly and concisely\")\n",
    "    system_prompt = f\"You are a Product Manager with 30 years of experience in the US as SaaS PM. You are very patient and understanding, explain the questions that a fresher in PM askes in the domain of Product management and Business Management. Also suggest some Youtube videos to watch on the concept asked, books to read or any resource that might be helpful. Explain the concept {level_description}\"\n",
    "\n",
    "    print(f\"DEBUG: Using System Prompt: '{system_prompt}'\")  # For checking\n",
    "\n",
    "    try:\n",
    "        # Note: stream = True is the key change here!\n",
    "        stream = client_Session.chat.completions.create(\n",
    "            model = \"gpt-4o-mini\",\n",
    "            messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_question}],\n",
    "            temperature = 0.7,\n",
    "            stream = True,  # Enable streaming (magic happens here)\n",
    "        )\n",
    "\n",
    "        # Iterate through the response chunks\n",
    "        full_response = \"\"  # Keep track of the full response if needed later\n",
    "\n",
    "        # Loop through each chunk of the response as it arrives\n",
    "        for chunk in stream:\n",
    "            # Check if this chunk contains actual text content\n",
    "            if chunk.choices[0].delta and chunk.choices[0].delta.content:\n",
    "                # Extract the text from this chunk\n",
    "                text_chunk = chunk.choices[0].delta.content\n",
    "                # Add this chunk to our growing response\n",
    "                full_response += text_chunk\n",
    "                # 'yield' is special - it sends the current state of the response to Gradio\n",
    "                # This makes the text appear to be typing in real-time\n",
    "                \n",
    "                yield full_response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during streaming: {e}\")\n",
    "        yield f\"Sorry, I encountered an error: {e}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56d9ca49-08f5-48c4-a4e1-3174aab4b06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function to display markdown nicely\n",
    "from IPython.display import display, Markdown\n",
    "def print_markdown(text):\n",
    "    \"\"\"Displays text as Markdown in Jupyter.\"\"\"\n",
    "    display(Markdown(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9632e863-fff4-495b-9628-8d91f6139296",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrudu\\anaconda3\\Lib\\site-packages\\gradio\\interface.py:418: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* Running on public URL: https://056e621860b72629ca.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
      "DEBUG: Using System Prompt: 'You are a Product Manager with 30 years of experience in the US as SaaS PM. You are very patient and understanding, explain the questions that a fresher in PM askes in the domain of Product management and Business Management. Also suggest some Youtube videos to watch on the concept asked, books to read or any resource that might be helpful. Explain the concept Like I'm Undergraduation student'\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "Product_Ai_tutor = gr.Interface(fn=stream_ai_tutor_response,\n",
    "             inputs = [gr.Textbox(lines = 4, placeholder = \"Ask your questions...\", label = \"Your Question\"),\n",
    "                      gr.Slider(\n",
    "                          minimum = 1, \n",
    "                          maximum = 5, \n",
    "                          step = 1, \n",
    "                          value = 3, \n",
    "                          label = \"Explanation complexity, 1 the most simplest and 5 the most complex\"\n",
    "                          ),\n",
    "                          ],\n",
    "             #outputs = gr.Textbox(lines = 20,label = \"Your AI Product Tutor's answer\"),\n",
    "            outputs = gr.Markdown(label=\"Your AI Product Tutor's answer\",container = True, height = 500),\n",
    "             title = \"ðŸ¤– AI Product Tutor!\",\n",
    "             description = \"Struggling with Product Management concepts? Meet your Product AI Tutor â€” ask anything and get clear, step-by-step guidance with the most practical and detailed explanations\",\n",
    "             allow_flagging = \"never\") \n",
    "\n",
    "Product_Ai_tutor.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
